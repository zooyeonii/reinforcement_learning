{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from random import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjacency matrix\n",
    "def adjacency_matrix(n):\n",
    "    a = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j :\n",
    "                a[i,j] = 0\n",
    "            elif i<j :\n",
    "                a[i,j] = randint(0,1)\n",
    "            else:\n",
    "                a[i,j] = a[j,i]\n",
    "    return a \n",
    "\n",
    "def rand_func(n, lower, upper):\n",
    "    return np.random.randint(lower, upper, size = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. adjacency matrix = \n",
      " [[0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.]]\n",
      "connection = \n",
      " [5. 6. 7. 5. 8. 9. 5. 4. 3. 6. 7. 5.]\n",
      "2. number of publish = \n",
      " [37 12 72  9 75  5 79 64 16  1 76 71]\n",
      "3. number of subscribe = \n",
      " [ 6 25 50 20 18 84 11 28 29 14 50 68]\n",
      "4. neighborhood =\n",
      " [33. 40. 41. 35. 48. 54. 31. 24. 22. 42. 40. 30.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "#0. number of clients\n",
    "num_c = 12\n",
    "\n",
    "#1. adjacency matrix / connection\n",
    "A = adjacency_matrix (num_c)\n",
    "connection = np.sum(A, axis=1)\n",
    "\n",
    "#2. number of publish\n",
    "num_pub = rand_func(num_c, 0, 100)\n",
    "\n",
    "#3. number of subscribe\n",
    "num_sub = rand_func(num_c, 0, 100)\n",
    "\n",
    "#4. neighborhood\n",
    "def neighborhood():\n",
    "    neighborhood = np.zeros(num_c)\n",
    "    for i in range(num_c):\n",
    "        for j in range(num_c):\n",
    "            if A[i,j]==1 :\n",
    "                neighborhood[i]+=connection[j]\n",
    "    return neighborhood\n",
    "\n",
    "print(\"1. adjacency matrix = \\n\",A)\n",
    "print(\"connection = \\n\",connection)\n",
    "print(\"2. number of publish = \\n\", num_pub)\n",
    "print(\"3. number of subscribe = \\n\", num_sub)\n",
    "print(\"4. neighborhood =\\n\", neighborhood())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rargmax(vector):\n",
    "    # amax는 최고 값을 가지는 index를 무작위로 선택한다. \n",
    "    m = np.amax(vector)\n",
    "    indices = np.nonzero(vector == m)[0]\n",
    "    return random.choice(indices)\n",
    "def sum_pub_minus_sub(v):\n",
    "    sum_pub =0; sum_sub =0\n",
    "    seq = sorted(v);\n",
    "    for i in range(len(num_pub)):\n",
    "        for j in range(len(seq)):\n",
    "            if i==seq[j]:\n",
    "                sum_pub+=num_pub[i]\n",
    "                sum_sub+=num_sub[i]            \n",
    "    return sum_pub-sum_sub\n",
    "\n",
    "def sum_connection(v):\n",
    "    sum_conn = 0\n",
    "    seq = sorted(v)\n",
    "    for i in range(len(connection)):\n",
    "        for j in range(len(seq)):\n",
    "            if i==seq[j]:\n",
    "                sum_conn += connection[i]\n",
    "    return sum_conn\n",
    "def sum_neighbor(v):\n",
    "    sum_ne =0\n",
    "    neighbor = neighborhood()\n",
    "    seq = sorted(v)\n",
    "    for i in range(len(neighbor)):\n",
    "        for j in range(len(seq)):\n",
    "            if i==seq[j]:\n",
    "                sum_ne += neighbor[i]\n",
    "    return sum_ne\n",
    "#sum_neighbor([0,1])\n",
    "#sum_pub_minus_sub([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = num_c   # number of active peer\n",
    "action_size = 3 # +1 / 0 / -1\n",
    "num_episodes = 10\n",
    "rList=[]  # step 별 reward 저장 \n",
    "Q = np.zeros([state_size, action_size])\n",
    "max_reward = [] #lists to contain total rewards \n",
    "active_peer_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Episode  1 -------\n",
      "step:  0  active peer list : [0]\n",
      "reward : step은 0 리워드는, 36.52\n",
      "step 0 에서 Q는 [[ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.   36.52  0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]]\n",
      "new_state는  5\n",
      "step:  1  active peer list : [10]\n",
      "reward : step은 1 리워드는, 51.56\n",
      "step 1 에서 Q는 [[ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.   88.08  0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]]\n",
      "new_state는  5\n",
      "step:  2  active peer list : [8]\n",
      "reward : step은 2 리워드는, -4.96\n",
      "step 2 에서 Q는 [[ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.   83.12  0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]]\n",
      "new_state는  5\n",
      "step:  3  active peer list : [3]\n",
      "reward : step은 3 리워드는, -12.37\n",
      "step 3 에서 Q는 [[ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.   70.75  0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]]\n",
      "new_state는  5\n",
      "step:  4  active peer list : [8]\n",
      "reward : step은 4 리워드는, -4.96\n",
      "step 4 에서 Q는 [[ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.   65.79  0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]\n",
      " [ 0.    0.    0.  ]]\n",
      "new_state는  5\n",
      "step:  5  active peer list : [2]\n",
      "reward : step은 5 리워드는, 44.85\n",
      "step 5 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   110.64   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "step:  6  active peer list : [10]\n",
      "reward : step은 6 리워드는, 51.56\n",
      "step 6 에서 Q는 [[  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.  162.2   0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]\n",
      " [  0.    0.    0. ]]\n",
      "new_state는  5\n",
      "step:  7  active peer list : [0]\n",
      "reward : step은 7 리워드는, 36.52\n",
      "step 7 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   198.72   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "-----Episode  2 -------\n",
      "step:  0  active peer list : [9]\n",
      "reward : step은 0 리워드는, -21.75\n",
      "step 0 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   176.97   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "step:  1  active peer list : [10]\n",
      "reward : step은 1 리워드는, 51.56\n",
      "step 1 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   228.53   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "step:  2  active peer list : [1]\n",
      "reward : step은 2 리워드는, -20.67\n",
      "step 2 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   207.86   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "step:  3  active peer list : [5]\n",
      "reward : step은 3 리워드는, -265.62\n",
      "step 3 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   -57.76   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  5\n",
      "step:  4  active peer list : [0]\n",
      "reward : step은 4 리워드는, 35.52\n",
      "step 4 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   -57.76  35.52]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  6\n",
      "step:  5  active peer list : [9]\n",
      "reward : step은 5 리워드는, -22.75\n",
      "step 5 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   -57.76  35.52]\n",
      " [  0.   -22.75   0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  6\n",
      "step:  6  active peer list : [2]\n",
      "reward : step은 6 리워드는, 42.85\n",
      "step 6 에서 Q는 [[  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.   -57.76  35.52]\n",
      " [  0.   -22.75  42.85]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]\n",
      " [  0.     0.     0.  ]]\n",
      "new_state는  7\n",
      "step:  7  active peer list : [5]\n",
      "reward : step은 7 리워드는, -267.62\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   35.52]\n",
      " [   0.    -22.75   42.85]\n",
      " [   0.   -267.62    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  3 -------\n",
      "step:  0  active peer list : [6]\n",
      "reward : step은 0 리워드는, 73.19\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   42.85]\n",
      " [   0.   -267.62    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [7]\n",
      "reward : step은 1 리워드는, 23.0\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [6]\n",
      "reward : step은 2 리워드는, 71.19\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [4]\n",
      "reward : step은 3 리워드는, 150.0\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [   0.    150.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  4  active peer list : [6]\n",
      "reward : step은 4 리워드는, 71.19\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [   0.    221.19    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [8]\n",
      "reward : step은 5 리워드는, -7.96\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [   0.    213.23    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  6  active peer list : [5]\n",
      "reward : step은 6 리워드는, -268.62\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [   0.    -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [11]\n",
      "reward : step은 7 리워드는, 2.12\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  116.04]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [  73.31  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  4 -------\n",
      "step:  0  active peer list : [2]\n",
      "reward : step은 0 리워드는, 43.85\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   23.  ]\n",
      " [   0.   -267.62   71.19]\n",
      " [  73.31  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [9]\n",
      "reward : step은 1 리워드는, -23.75\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62   71.19]\n",
      " [  73.31  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [2]\n",
      "reward : step은 2 리워드는, 41.85\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  115.16]\n",
      " [  73.31  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [11]\n",
      "reward : step은 3 리워드는, 2.12\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  115.16]\n",
      " [ 117.28  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [2]\n",
      "reward : step은 4 리워드는, 41.85\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  159.13]\n",
      " [ 117.28  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [4]\n",
      "reward : step은 5 리워드는, 151.0\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  159.13]\n",
      " [ 310.13  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [0]\n",
      "reward : step은 6 리워드는, 33.52\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  343.65]\n",
      " [ 310.13  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [10]\n",
      "reward : step은 7 리워드는, 49.56\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76   66.85]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  343.65]\n",
      " [ 393.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  5 -------\n",
      "step:  0  active peer list : [6]\n",
      "reward : step은 0 리워드는, 73.19\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75   47.44]\n",
      " [   0.   -267.62  343.65]\n",
      " [ 393.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [6]\n",
      "reward : step은 1 리워드는, 72.19\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  343.65]\n",
      " [ 393.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [4]\n",
      "reward : step은 2 리워드는, 150.0\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  543.21]\n",
      " [ 393.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [4]\n",
      "reward : step은 3 리워드는, 151.0\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  543.21]\n",
      " [ 694.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [4]\n",
      "reward : step은 4 리워드는, 150.0\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  844.21]\n",
      " [ 694.21  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [8]\n",
      "reward : step은 5 리워드는, -6.96\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  844.21]\n",
      " [ 837.25  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [9]\n",
      "reward : step은 6 리워드는, -24.75\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  812.5 ]\n",
      " [ 837.25  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [5]\n",
      "reward : step은 7 리워드는, -267.62\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  120.63]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  812.5 ]\n",
      " [ 544.88  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  6 -------\n",
      "step:  0  active peer list : [3]\n",
      "reward : step은 0 리워드는, -13.37\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  415.84]\n",
      " [   0.   -267.62  812.5 ]\n",
      " [ 544.88  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [7]\n",
      "reward : step은 1 리워드는, 23.0\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  812.5 ]\n",
      " [ 544.88  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [10]\n",
      "reward : step은 2 리워드는, 48.56\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  593.44]\n",
      " [ 544.88  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [10]\n",
      "reward : step은 3 리워드는, 49.56\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  593.44]\n",
      " [ 643.    -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [7]\n",
      "reward : step은 4 리워드는, 22.0\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  665.  ]\n",
      " [ 643.    -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [0]\n",
      "reward : step은 5 리워드는, 34.52\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  665.  ]\n",
      " [ 699.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [0]\n",
      "reward : step은 6 리워드는, 33.52\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  733.04]\n",
      " [ 699.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [10]\n",
      "reward : step은 7 리워드는, 49.56\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  402.47]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  733.04]\n",
      " [ 782.6   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  7 -------\n",
      "step:  0  active peer list : [6]\n",
      "reward : step은 0 리워드는, 73.19\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  835.5 ]\n",
      " [   0.   -267.62  733.04]\n",
      " [ 782.6   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [9]\n",
      "reward : step은 1 리워드는, -23.75\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  733.04]\n",
      " [ 782.6   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [8]\n",
      "reward : step은 2 리워드는, -7.96\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  774.64]\n",
      " [ 782.6   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [1]\n",
      "reward : step은 3 리워드는, -22.67\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  774.64]\n",
      " [ 751.97  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [6]\n",
      "reward : step은 4 리워드는, 71.19\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  823.16]\n",
      " [ 751.97  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [3]\n",
      "reward : step은 5 리워드는, -14.37\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  823.16]\n",
      " [ 808.79  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [0]\n",
      "reward : step은 6 리워드는, 33.52\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  842.31]\n",
      " [ 808.79  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [11]\n",
      "reward : step은 7 리워드는, 2.12\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  908.69]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  842.31]\n",
      " [ 844.43  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  8 -------\n",
      "step:  0  active peer list : [1]\n",
      "reward : step은 0 리워드는, -21.67\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  709.29]\n",
      " [   0.   -267.62  842.31]\n",
      " [ 844.43  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [5]\n",
      "reward : step은 1 리워드는, -267.62\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  842.31]\n",
      " [ 844.43  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [2]\n",
      "reward : step은 2 리워드는, 41.85\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  886.28]\n",
      " [ 844.43  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [5]\n",
      "reward : step은 3 리워드는, -267.62\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  886.28]\n",
      " [ 618.66  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [10]\n",
      "reward : step은 4 리워드는, 48.56\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  667.22]\n",
      " [ 618.66  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [1]\n",
      "reward : step은 5 리워드는, -22.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  667.22]\n",
      " [ 644.55  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [0]\n",
      "reward : step은 6 리워드는, 33.52\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  678.07]\n",
      " [ 644.55  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [9]\n",
      "reward : step은 7 리워드는, -23.75\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  687.62]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  678.07]\n",
      " [ 654.32  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  9 -------\n",
      "step:  0  active peer list : [3]\n",
      "reward : step은 0 리워드는, -13.37\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  574.69]\n",
      " [   0.   -267.62  678.07]\n",
      " [ 654.32  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [6]\n",
      "reward : step은 1 리워드는, 72.19\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  678.07]\n",
      " [ 654.32  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [10]\n",
      "reward : step은 2 리워드는, 48.56\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  702.88]\n",
      " [ 654.32  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [9]\n",
      "reward : step은 3 리워드는, -23.75\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  702.88]\n",
      " [ 679.13  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [2]\n",
      "reward : step은 4 리워드는, 41.85\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  720.98]\n",
      " [ 679.13  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [11]\n",
      "reward : step은 5 리워드는, 2.12\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  720.98]\n",
      " [ 723.1   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [5]\n",
      "reward : step은 6 리워드는, -268.62\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  454.48]\n",
      " [ 723.1   -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [8]\n",
      "reward : step은 7 리워드는, -6.96\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  561.32]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  454.48]\n",
      " [ 447.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "-----Episode  10 -------\n",
      "step:  0  active peer list : [5]\n",
      "reward : step은 0 리워드는, -266.62\n",
      "step 0 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  750.26]\n",
      " [   0.   -267.62  454.48]\n",
      " [ 447.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  6\n",
      "step:  1  active peer list : [8]\n",
      "reward : step은 1 리워드는, -6.96\n",
      "step 1 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  454.48]\n",
      " [ 447.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  2  active peer list : [2]\n",
      "reward : step은 2 리워드는, 41.85\n",
      "step 2 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  489.37]\n",
      " [ 447.52  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  3  active peer list : [6]\n",
      "reward : step은 3 리워드는, 72.19\n",
      "step 3 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  489.37]\n",
      " [ 561.56  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  4  active peer list : [6]\n",
      "reward : step은 4 리워드는, 71.19\n",
      "step 4 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  632.75]\n",
      " [ 561.56  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  5  active peer list : [7]\n",
      "reward : step은 5 리워드는, 23.0\n",
      "step 5 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  632.75]\n",
      " [ 655.75  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n",
      "step:  6  active peer list : [0]\n",
      "reward : step은 6 리워드는, 33.52\n",
      "step 6 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  689.27]\n",
      " [ 655.75  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  8\n",
      "step:  7  active peer list : [8]\n",
      "reward : step은 7 리워드는, -6.96\n",
      "step 7 에서 Q는 [[   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.    -57.76  483.64]\n",
      " [   0.    -22.75  447.52]\n",
      " [   0.   -267.62  689.27]\n",
      " [ 682.31  -55.39    0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]\n",
      " [   0.      0.      0.  ]]\n",
      "new_state는  7\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_episodes):\n",
    "    #1. 환경을 초기화하고, 첫 state를 가져온다.\n",
    "    state = 5\n",
    "    rAll = 0\n",
    "    done = False \n",
    "    max_steps = 8\n",
    "    step =0\n",
    "    # Q-table Learning algorithm\n",
    "    print(\"-----Episode \", i+1, \"-------\")\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        reward = 0\n",
    "        keep_stay = 0 # counting step\n",
    "        action = rargmax(Q[state,:])\n",
    "        active_peer_list = []\n",
    "            \n",
    "            \n",
    "        # Get new state and reward from environment\n",
    "        if action == 0 : \n",
    "            keep_stay = 0 \n",
    "            if state < 0 :\n",
    "                new_state = state\n",
    "                reward = -10000000\n",
    "                done = True\n",
    "            else :\n",
    "                new_state = state-1\n",
    "        elif action ==1:\n",
    "            new_state = state\n",
    "            keep_stay +=1\n",
    "        else:\n",
    "            keep_stay = 0\n",
    "            if state > num_c :\n",
    "                new_sate = state\n",
    "                reward = -1000000\n",
    "                done = True\n",
    "            else :\n",
    "                new_state = state +1\n",
    "                    \n",
    "        if done == True:\n",
    "            break\n",
    "        #select #(state) of active peers (print the peers' number)        \n",
    "        active_peer_list.append(random.randint(0,num_c-1))\n",
    "        print(\"step: \", step, \" active peer list :\", active_peer_list)\n",
    "            \n",
    "        #evaluate reward by those peers! \n",
    "            #(50-num_active)+(sum_publish-sum_subscribe)*(sum_connection/num_c)*(sum_neighborhood/num_c)\n",
    "        reward = (num_c/2-new_state)+(sum_pub_minus_sub(active_peer_list))*(sum_connection(active_peer_list)/num_c)*(sum_neighbor(active_peer_list)/num_c)\n",
    "        reward = round(reward,2)\n",
    "        print(\"reward : step은\", step,\"리워드는,\", reward)\n",
    "        #add list of active peers per \n",
    "        # Update Q-table \n",
    "        Q[state,action] = reward + np.max(Q[new_state,:])\n",
    "        print(\"step\",step,\"에서\",\"Q는\",Q)\n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        print(\"new_state는 \", new_state)\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
